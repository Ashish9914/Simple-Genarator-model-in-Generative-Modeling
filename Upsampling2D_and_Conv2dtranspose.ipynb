{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Upsampling2D and Conv2dtranspose.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y3-0vvr9Yvf",
        "colab_type": "text"
      },
      "source": [
        "Two common types of layers that can be used in the generator model are a upsample layer (UpSampling2D) that simply doubles the dimensions of the input and the transpose convolutional layer (Conv2DTranspose) that performs an inverse convolution operation.\n",
        "\n",
        "The generator works by taking a random point from the latent space as input and outputting a complete image, in a one-shot manner.\n",
        "\n",
        "A traditional convolutional neural network for image classification, and related tasks, will use pooling layers to downsample input images. For example, an average pooling or max pooling layer will reduce the feature maps from a convolutional by half on each dimension, resulting in an output that is one quarter the area of the input.\n",
        "\n",
        "Convolutional layers themselves also perform a form of downsampling by applying each filter across the input images or feature maps; the resulting activations are an output feature map that is smaller because of the border effects. Often padding is used to counter this effect.\n",
        "\n",
        "The generator model in a GAN requires an inverse operation of a pooling layer in a traditional convolutional layer. It needs a layer to translate from coarse salient features to a more dense and detailed output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UEaiOtQ9_tP",
        "colab_type": "text"
      },
      "source": [
        "How to use upsampling layer. it just doubles the dimensions of the input image or the lantent space for example from 2,2 to 4,4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pogivlJR95OU",
        "colab_type": "code",
        "outputId": "7641013b-b950-4748-d6b1-34398ed3b8be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        }
      },
      "source": [
        "from numpy import asarray\n",
        "from keras.models import Sequential\n",
        "from keras.layers import UpSampling2D\n",
        "# define input data\n",
        "X = asarray([[1, 2],\n",
        "\t\t\t [3, 4]])\n",
        "# show input data for context\n",
        "print(X)\n",
        "# reshape input data into one sample a sample with a channel\n",
        "X = X.reshape((1, 2, 2, 1))\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(UpSampling2D(input_shape=(2, 2, 1)))\n",
        "# summarize the model\n",
        "model.summary()\n",
        "# make a prediction with the model\n",
        "yhat = model.predict(X)\n",
        "# reshape output to remove channel to make printing easier\n",
        "yhat = yhat.reshape((4, 4))\n",
        "# summarize output\n",
        "print(yhat)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[[1 2]\n",
            " [3 4]]\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "up_sampling2d_1 (UpSampling2 (None, 4, 4, 1)           0         \n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "[[1. 1. 2. 2.]\n",
            " [1. 1. 2. 2.]\n",
            " [3. 3. 4. 4.]\n",
            " [3. 3. 4. 4.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mfg0d2P_gmE",
        "colab_type": "text"
      },
      "source": [
        "The model has only the Conv2DTranspose layer, which takes 2×2 grayscale images as input directly and outputs the result of the operation.\n",
        "\n",
        "The Conv2DTranspose both upsamples and performs a convolution. As such, we must specify both the number of filters and the size of the filters as we do for Conv2D layers. Additionally, we must specify a stride of (2,2) because the upsampling is achieved by the stride behavior of the convolution on the input.\n",
        "\n",
        "Specifying a stride of (2,2) has the effect of spacing out the input. Specifically, rows and columns of 0.0 values are inserted to achieve the desired stride.\n",
        "\n",
        "In this example, we will use one filter, with a 1×1 kernel and a stride of 2×2 so that the 2×2 input image is upsampled to 4×4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_uEoxsB_h0F",
        "colab_type": "code",
        "outputId": "52eb4a01-1374-4c09-f44c-e70d944e9ac4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        }
      },
      "source": [
        "from numpy import asarray\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2DTranspose\n",
        "# define input data\n",
        "X = asarray([[1, 2],\n",
        "\t\t\t [3, 4]])\n",
        "# show input data for context\n",
        "print(X)\n",
        "# reshape input data into one sample a sample with a channel\n",
        "X = X.reshape((1, 2, 2, 1))\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Conv2DTranspose(1, (1,1), strides=(2,2), input_shape=(2, 2, 1)))\n",
        "# summarize the model\n",
        "model.summary()\n",
        "# define weights that they do nothing\n",
        "weights = [asarray([[[[1]]]]), asarray([0])]\n",
        "# store the weights in the model\n",
        "model.set_weights(weights)\n",
        "# make a prediction with the model\n",
        "yhat = model.predict(X)\n",
        "# reshape output to remove channel to make printing easier\n",
        "yhat = yhat.reshape((4, 4))\n",
        "# summarize output\n",
        "print(yhat)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[[1 2]\n",
            " [3 4]]\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_transpose_1 (Conv2DTr (None, 4, 4, 1)           2         \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "[[1. 0. 2. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [3. 0. 4. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85CXV_BwAMRG",
        "colab_type": "text"
      },
      "source": [
        "Simple Generator Model With the UpSampling2D Layer\n",
        "\n",
        "\n",
        "The UpSampling2D layer is simple and effective, although does not perform any learning.\n",
        "\n",
        "It is not able to fill in useful detail in the upsampling operation. To be useful in a GAN, each UpSampling2D layer must be followed by a Conv2D layer that will learn to interpret the doubled input and be trained to translate it into meaningful detail.\n",
        "\n",
        "We can demonstrate this with an example.\n",
        "\n",
        "In this case, our little GAN generator model must produce a 10×10 image and take a 100 element vector from the latent space as input.\n",
        "\n",
        "First, a Dense fully connected layer can be used to interpret the input vector and create a sufficient number of activations (outputs) that can be reshaped into a low-resolution version of our output image, in this case, 128 versions of a 5×5 image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8m2W6r2ATsl",
        "colab_type": "code",
        "outputId": "e54e8920-b9be-40e9-b5f2-c043df8d49cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import UpSampling2D\n",
        "from keras.layers import Conv2D\n",
        "# define model\n",
        "model = Sequential()\n",
        "# define input shape, output enough activations for for 128 5x5 image\n",
        "model.add(Dense(128 * 5 * 5, input_dim=100))\n",
        "# reshape vector of activations into 128 feature maps with 5x5\n",
        "model.add(Reshape((5, 5, 128)))\n",
        "# double input from 128 5x5 to 1 10x10 feature map\n",
        "model.add(UpSampling2D())\n",
        "# fill in detail in the upsampled feature maps and output a single image\n",
        "model.add(Conv2D(1, (3,3), padding='same'))\n",
        "# summarize model\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 3200)              323200    \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 10, 10, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 10, 10, 1)         1153      \n",
            "=================================================================\n",
            "Total params: 324,353\n",
            "Trainable params: 324,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuYn895GAo5I",
        "colab_type": "text"
      },
      "source": [
        "Simple Generator Model With the Conv2DTranspose Layer\n",
        "\n",
        "The Conv2DTranspose is more complex than the UpSampling2D layer, but it is also effective when used in GAN models, specifically the generator model.\n",
        "\n",
        "Either approach can be used, although the Conv2DTranspose layer is preferred, perhaps because of the simpler generator models and possibly better results, although GAN performance and skill is notoriously difficult to quantify.\n",
        "\n",
        "We can demonstrate using the Conv2DTranspose layer in a generator model with another simple example.\n",
        "\n",
        "In this case, our little GAN generator model must produce a 10×10 image and take a 100-element vector from the latent space as input, as in the previous UpSampling2D example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlB4nGmyAvML",
        "colab_type": "code",
        "outputId": "db446d5c-65dc-4652-e80d-ea162ec8a7ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import Conv2D\n",
        "# define model\n",
        "model = Sequential()\n",
        "# define input shape, output enough activations for for 128 5x5 image\n",
        "model.add(Dense(128 * 5 * 5, input_dim=100))\n",
        "# reshape vector of activations into 128 feature maps with 5x5\n",
        "model.add(Reshape((5, 5, 128)))\n",
        "# double input from 128 5x5 to 1 10x10 feature map\n",
        "model.add(Conv2DTranspose(1, (3,3), strides=(2,2), padding='same'))\n",
        "# summarize model\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 3200)              323200    \n",
            "_________________________________________________________________\n",
            "reshape_2 (Reshape)          (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 10, 10, 1)         1153      \n",
            "=================================================================\n",
            "Total params: 324,353\n",
            "Trainable params: 324,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}